Abstract 
Context Computed tomography coronary angiography (CTCA) has become a common diagnostic test, yet there are little data on its associated cancer risk. The recent Biological Effects of Ionizing Radiation (BEIR) VII Phase 2 report provides a framework for estimating lifetime attributable risk (LAR) of cancer incidence associated with radiation exposure from a CTCA study, using the most current data available on health effects of radiation.
Objectives To determine the LAR of cancer incidence associated with radiation exposure from a 64-slice CTCA study and to evaluate the influence of age, sex, and scan protocol on cancer risk.
Design, Setting, and Patients Organ doses from 64-slice CTCA to standardized phantom (computational model) male and female patients were estimated using Monte Carlo simulation methods, using standard spiral CT protocols. Age- and sex-specific LARs of individual cancers were estimated using the approach of BEIR VII and summed to obtain whole-body LARs.
Main Outcome Measures Whole-body and organ LARs of cancer incidence.
Results Organ doses ranged from 42 to 91 mSv for the lungs and 50 to 80 mSv for the female breast. Lifetime cancer risk estimates for standard cardiac scans varied from 1 in 143 for a 20-year-old woman to 1 in 3261 for an 80-year-old man. Use of simulated electrocardiographically controlled tube current modulation (ECTCM) decreased these risk estimates to 1 in 219 and 1 in 5017, respectively. Estimated cancer risks using ECTCM for a 60-year-old woman and a 60-year-old man were 1 in 715 and 1 in 1911, respectively. A combined scan of the heart and aorta had higher LARs, up to 1 in 114 for a 20-year-old woman. The highest organ LARs were for lung cancer and, in younger women, breast cancer.
Conclusions These estimates derived from our simulation models suggest that use of 64-slice CTCA is associated with a nonnegligible LAR of cancer. This risk varies markedly and is considerably greater for women, younger patients, and for combined cardiac and aortic scans.
Coronary artery disease (CAD) is the leading cause of death in men and women in the United States, accounting for 1 in 5 deaths, and a major cause of health care expenditures, with annual costs estimated at $142 billion.1 While the gold standard for CAD diagnosis remains conventional coronary angiography, its associated costs and morbidity, including a 1.7% rate of major complications,2 have led to the development of noninvasive modalities for CAD diagnosis. Since its approval in 2004, 64-slice computed tomography coronary angiography (CTCA) has generated particular interest due to its visualization of the coronary arteries with a spatial resolution as low as 0.4 mm, resulting in high diagnostic sensitivity and specificity and a per-patient negative predictive value greater than 95% in most series.3
While the relative role of CTCA within the array of noninvasive imaging modalities is currently not well defined, it has been predicted that CTCA may emerge as the diagnostic test of choice for patients with intermediate pretest probability of disease.4 One setting in which CTCA has been proposed to be particularly useful is in the rapid evaluation of emergency department patients with chest pain.5 Approximately 6 million patients are evaluated annually for chest pain in US emergency departments, and while only 15% to 25% are ultimately diagnosed with an acute coronary syndrome, depending on the setting, up to 72% will be admitted to the hospital.6 Many of these patients will have serial cardiac enzyme levels measured, and if those levels are normal, will then have stress testing performed. However, CTCA offers the possibility of assessing coronary artery patency in a scan taking less than 20 minutes, shortly after arrival in the emergency department and prior to the enzymatic exclusion of myocardial injury. The installation base of CTCA-capable scanners has increased rapidly, and consistent with this, the volume of CTCAs performed also has increased.7
The general perception is that a cancer risk is associated with CTCA,8 although few quantitative data are available. The recently published American Heart Association scientific statement on cardiac CT cites the Food and Drug Administration Web site, which states that a 10-mSv CT study may be associated with an increase in the possibility of fatal cancer of approximately 1 in 2000 cases.9 However, it remains unclear how this risk is affected by patient age, sex, and scan protocol. This information is of vital importance in the development of strategies for the selection of noninvasive tests for CAD, as the availability and utilization of CTCA will likely increase and its use may extend to even younger patients in the future.
The National Academies' Biological Effects of Ionizing Radiation 7th Report (BEIR VII Phase 2), presented to Congress in June 2005 and published in 2006, provides a framework for estimating cancer risk associated with radiation exposure from CTCA.10 BEIR VII develops risk estimates for cancer from exposure to low-level ionizing radiation using the most current data and epidemiological models available, incorporating data from atomic bomb survivor studies as well as medical and occupational radiation studies. Its review of available data supports the so-called linear no-threshold (LNT) risk model for low-dose exposures to low linear energy transfer radiation such as x-rays, whereby the risk of cancer proceeds in linear fashion with no lower threshold.
The purpose of this study was to determine the lifetime attributable risk (LAR) of cancer incidence associated with radiation exposure from a single CTCA study, using the approach proposed in BEIR VII, and to determine how this risk is influenced by patient age, sex, and scan protocol. Scan protocols considered included (1) standard cardiac CTCA studies; (2) a protocol using electrocardiographically controlled tube current modulation (ECTCM), a dose reduction strategy that reduces radiation during part of the cardiac cycle; (3) a protocol including a scan of both the heart and aorta, extending cranially to include the aortic arch, as is commonly performed for patients with coronary artery bypass grafts and in the “triple rule-out” of CAD, aortic dissection, and pulmonary embolism; and (4) a protocol using both ECTCM and aortic scanning.
Methods 
Our general approach was to determine equivalent doses to individual organs from CTCA using Monte Carlo simulations, and then determine cancer risks from these doses using the approach of BEIR VII.
Monte Carlo Simulations 
Monte Carlo simulations were implemented using the ImpactDose package (VAMP GmbH, Erlangen, Germany), which estimates radiation dose to organs by modeling photon transport from CT through standardized male and female anthropomorphic mathematical phantoms. This model yields dosimetric estimates of primary radiation from measurements and manufacturer specifications, and of scattered radiation using Monte Carlo calculations based on the approach of the Gesellschaft für Strahlen- und Umweltforschung.11
A 64-slice scanner (SOMATOM Sensation 64, Siemens AG, Munich, Germany) was modeled. Standard scan parameters were used, including tube voltage of 120 kVp, tube current-time product of 170 mAs, gantry rotation time of 0.33 seconds, slice thickness of 0.6 mm, slice increment per rotation of 3.8 mm, and pitch of 0.2. Scan range was 15 cm in the case of a standard cardiac CT and was extended another 10 cm cranially for studies including the aorta. Electrocardiographically controlled tube current modulation was simulated by reducing tube current by 35%, a typical mean reduction in current for ECTCM in 64-slice CTCA.12 Eight Monte Carlo simulations were performed, representing each combination of sex, incorporation of ECTCM, and inclusion of the aorta.
BEIR VII Risk Modeling 
For each age, sex, and organ, the LAR of cancer incidence from a 100-mSv organ equivalent dose was determined using Table 12D-1 of the BEIR VII report. If data were not available for a specific age, then linear interpolation was performed from the 2 nearest tabulated ages. This LAR from a theoretical 100-mSv organ dose was scaled linearly based on the actual organ dose determined in the Monte Carlo simulation. For example, the lung equivalent dose for a 40-year-old woman from a standard CTCA scan is 74 mSv; the LAR of lung cancer incidence for a 40-year-old woman from a 100-mSv lung dose is 240 cases per 100 000 by the BEIR VII preferred model, so the LAR from a 74-mSv dose is (74/100) × (240/100 000) or 0.178%.
Organ-specific LARs of cancer incidence were estimated from organ equivalent doses for those malignancies specified in the BEIR VII report. Whole-body LAR was estimated by summing site-specific LARs for these organs and adding a composite equivalent dose for the BEIR VII category of “other” malignancies, relatively weighting each component by its tissue weighting factor as specified by the International Commission on Radiological Protection in its Publication 60.13 We repeated the analysis for all combinations of age (ranging from 20-80 years in yearly increments), sex, and scan type. Cancer risk modeling was performed using Excel 2003 (Microsoft Corp, Redmond, Washington).
Results 
Age, Sex, and Cancer Risk 
Doses from CTCA in the 8 protocols are summarized in Table 1. Estimated risks of cancer incidence attributable to a single CTCA scan are summarized in Figure 1. The LAR for a 20-year-old woman from a standard scan without ECTCM was 0.70%, or 1 in 143. Risks were particularly high for women in their 20s and decreased markedly as a function of age. For a 40-year-old woman, the LAR was 0.35% (1 in 284); for a 60-year-old, the LAR was 0.22% (1 in 466); and for an 80-year-old, the LAR was 0.075% (1 in 1338). Figure 2 displays the individual organ contributions to LAR from a single CTCA scan. In women, the primary contributors to risk were lung and breast cancer. The leading cause of cancer in women from a CTCA scan was breast cancer until 32 years of age, after which lung cancer risk exceeded that of breast cancer risk. At all ages, lung and breast cancer combined accounted for 80% to 85% of the attributable risk of cancer from a CTCA study in women.
Estimated risks were considerably lower in men. For a 20-year-old man, the LAR of cancer incidence from a single CTCA study was 0.15% (1 in 686), equivalent to the risk to a 70-year-old woman. Risks to men also decreased as a function of age, to 0.099% (1 in 1007) for a 40-year-old, 0.081% (1 in 1241) for a 60-year-old, and 0.044% (1 in 3261) for an 80-year-old.
Table 2 summarizes the relative risk (RR), in comparison to an 80-year-old man receiving a standard scan, of attributable cancer incidence in other patient groups. In comparison with an 80-year-old man, a 20-year-old man has a 5-fold RR of attributable cancer incidence from a CTCA scan. An 80-year-old woman has 2.4 times the risk, while a 20-year-old woman has 23 times the risk compared with an 80-year-old man.
Scan Protocols and Cancer Risk 
Tube current reduction by 35% corresponded to an estimated reduction in cancer risk by about 35%. For example, in 20-year-old women the risk decreased from 1 in 143 without ECTCM to 1 in 219 with ECTCM. There were similar findings at other ages and for men as well; eg, using ECTCM, LARs for 60-year-old women and men decreased to 1 in 715 and 1 in 1911, respectively. Extending the baseline scan by 10 cm cranially to include the aortic arch increased the LAR by 43% to 46% in men and 24% to 28% in women, depending on age. The lower increase in women was largely because breast dose did not increase proportionally with the extended scan.
Comment 
In this study, we observed a marked variation by age, sex, and scan protocol for cancer risk associated with radiation exposure from CTCA. Rather than a relatively constant risk of cancer in 1 person per 1000 to 2000 exposed,8 the LAR ranged from less than 0.02% (1 in 5017 for 80-year-old men with ECTCM) to nearly 1% (1 in 114 for 20-year-old women with aortic arch scanning).
Radiosensitivity of many organs such as the breast has been observed to decrease with age.14 Moreover, a long lag time is typical from acute radiation exposure to the development of malignancy, eg, a 12-year minimum latency period from radiation exposure to excess breast cancer risk has been described in Japanese atomic bomb survivors.15 Consistent with this, older patients in our study, who were both less radiosensitive and less likely to survive to the development of a radiation-attributable cancer, had lower LARs than did younger patients.
The LAR for women was greater than that for men at all ages, with the RR of female sex ranging from 2.4 at age 80 years to 4.8 at age 20 years. Two major factors account for this. While the lung dose was minimally higher to the female phantom than to the male phantom, what is strikingly different between women and men is their radiosensitivities. A 100-mSv lung dose is associated with an estimated excess risk of lung cancer of 346 cases per 100 000 in a 20-year-old woman, but only 149 cases per 100 000 in a 20-year-old man, according to BEIR VII data, and similarly at all ages. The second major difference between women and men is the risk of breast cancer attributable to CTCA, as the breast lies in the field of irradiation.
The risk estimates reported here provide practitioners with data that can be used to assess the risk vs benefit of CTCA in specific patients. However, the approach used in this study has several limitations. The estimates are not based on epidemiological data of actual malignancies in populations of patients receiving CTCAs; such data are not available and will not be available for the foreseeable future. Rather, these estimates are extrapolated based on the attributable cancer risk models developed in the BEIR VII report, as well as standard Monte Carlo methods modeling photon transport in CT. As such, this study provides a simplified approach, albeit one that we believe is the best available from current data. The Monte Carlo methods used are based on standardized geometrical phantoms, and thus do not incorporate the effect of patient habitus. Further research is needed to evaluate the association of body habitus with radiation dose and cancer risk.
The BEIR VII risk estimates were developed for the general US population, and as such are applicable for patients with typical life expectancy for age and sex. While this may be a reasonable assumption for many groups of patients who may receive CTCA, such as patients with chest pain but low pretest probability of disease presenting for emergency department evaluation and patients being screened for coronary disease, risk associated with CTCA may be lower in patients with decreased baseline life expectancy, for example in patients with cardiomyopathy, who may not survive long enough to develop a radiation-attributable cancer.
While the BEIR VII report provides a framework for estimating age-, sex-, and organ-specific cancer risks from a radiation exposure, it does not offer quantitative estimates of the uncertainty involved with such estimates. The report provides what it refers to as “subjective 95% confidence intervals” to quantify uncertainty in some exposure scenarios, incorporating uncertainty from 3 sources: sampling variability, transport from a Japanese to a US population, and the dose and dose-rate effectiveness factor (DDREF). For a radiation exposure in which each organ receives the same dose, subjective 95% confidence intervals for LAR of all-solid cancer incidence range from approximately half the estimated LAR to twice the estimated LAR (Table 12-6 in the report). These subjective 95% confidence intervals are not offered, however, for age-, sex-, and organ-specific LARs, which are estimated here for CTCA and summed to estimate age- and sex-specific all-cancer risks associated with CTCA. The lack of a quantitative characterization of the uncertainty in the LAR estimates is another limitation of our approach.
The BEIR VII Phase 2 committee was convened in 1998, after a Phase 1 committee formed to address the US Environmental Protection Agency's request of the National Academy of Sciences to evaluate the need for a reexamination of health effects of low levels of ionizing radiation had concluded that such reexamination was necessary. The 17 member Phase 2 panel was composed of international experts in a variety of fields relevant to the group's charge “to develop the best possible risk estimates for exposure to low-dose, low-linear energy transfer radiation in human subjects.”
The committee's work was supported by the US Environmental Protection Agency, Department of Defense, Department of Energy, Nuclear Regulatory Commission, and Department of Homeland Security, and conducted with the administrative assistance of the National Research Council's Board of Radiation Effects Research. A majority of the committee's meetings were open to the public, and all meetings involved extensive deliberations. The committee's work was open to public comments and members received formal presentations from representatives of governmental agencies, universities, nongovernmental organizations, and activist, public interest, and industry groups.10,16 The report was reviewed by another independent expert panel to ensure its objectivity, standards of evidence, and responsiveness to the study charge.
The BEIR VII risk models were developed based on a comprehensive review of the world literature on radiation epidemiology. It is impossible to reconcile every study in this complex literature with every other study, and there are differing interpretations of these data; therefore, despite the extensive efforts made to compose a highly expert committee, avoid conflicts of interest, and obtain diverse perspectives, some of the premises underlying the BEIR VII risk models are not uniformly agreed on and its applicability to different populations has been challenged. Uncertainties in the BEIR VII models include methods used to transport (apply) data from Japanese atomic bomb survivors to a US population with different baseline cancer rates, sampling variability in parameter estimates in the risk models, the choice of a DDREF, and accounting for differences in relative biological effectiveness between x-rays and other types of ionizing radiation.
Other radiation protection organizations, such as the International Commission on Radiological Protection,13 have selected a higher DDREF than that used in BEIR VII, typically 2.0 rather than 1.5. Using a higher DDREF would result in lower risks of cancer incidence than reported in this study. On the other hand, current radiation protection guidelines assign a radiation weighting factor of 1 to x-rays, although some biological evidence suggests that the biological effectiveness per unit-absorbed dose of x-rays may be twice that of high-energy photons.10 This may result in an underestimation of cancer risk associated with radiation exposure from CTCA using our methodology. Perhaps the most debated assumption of the BEIR VII models is the LNT relationship between dose and cancer risk. A number of organizations besides the BEIR VII committee have recently reviewed the LNT hypothesis (Box).17-23 While there are subtleties in the positions of each of these organizations, the majority basically conclude that LNT best fits the data and should remain the standard for radiation protection.
Box. Organizations With Positions on Linear No-Threshold (LNT) Model at <100 mSv 
•	Basically Supportive
US National Research Council Biological Effects of Ionizing Radiation (BEIR) VII Phase 2 (2006)10
International Commission on Radiological Protection (2005)17
US National Council on Radiation Protection and Measurements (2001)18
United Nations Scientific Committee on the Effects of Atomic Radiation (2000)19
UK National Radiological Protection Board (1995)20
•	LNT Is Oversimplification; Risk Estimates Should Not Be Used at <50 mSv
Health Physics Society (2004)21
•	LNT Overestimates Risk
France Academy of Sciences/National Academy of Medicine (2004)22
American Nuclear Society (2001)23
While the BEIR VII breast cancer risk models are based on the pooled analysis of Preston et al,24 which incorporates data from the Life Span Study (LSS) of Japanese atomic bomb survivors as well as cohorts of Massachusetts women treated for tuberculosis with chest fluoroscopy and Rochester women who had received x-ray therapy in infancy for thymic enlargement, the BEIR VII lung cancer models are based solely on LSS data. While the LSS cohort has advantages including its large size and high-quality cancer incidence and mortality data, its lung cancer mortality data are not compatible with data from cohorts of Massachusetts25 and Canadian26 tuberculosis patients treated with chest fluoroscopy between 1925 and 1954, in which radiation-related increases in lung cancer mortality were not noted.
Nevertheless, we believe that there are important differences between these tuberculosis patient cohorts and CTCA patients, making the LSS cohort at least as applicable to determine risk of lung cancer incidence associated with radiation exposure from CTCA. Radiation to the patients with tuberculosis was delivered in fractions of much lower dose (estimated lung equivalent dose of 11 mSv) and dose rate than radiation delivered to CTCA patients (lung dose up to 91 mSv), with over a week's time between sessions, potentially enabling repair of radiation damage,27 while many LSS patients received lung doses comparable to those received by CTCA patients. Moreover, as suggested in the BEIR VII report, the presence of tuberculosis may modify radiation-induced risk of cancer mortality. Consistent with this, in nontuberculous patients who received x-ray therapy for peptic ulcers in Chicago, Carr et al noted a radiation-related increase in lung cancer mortality, with a dose-response relationship compatible with that in the LSS population.28
The results of this study suggest that CTCA should be used particularly cautiously in the evaluation of young individuals, especially women, for whom alternative diagnostic modalities that do not involve the use of ionizing radiation should be considered, such as stress electrocardiography, echocardiography, or magnetic resonance imaging. If CTCA is considered as an alternative to invasive coronary angiography, the risks and benefits of each test require consideration. While radiation doses are typically greater in CTCA, invasive angiography is associated with a 1.7% risk of major complications, including vascular complications, stroke, and death in 0.11% of patients.2
In patients undergoing CTCA, dose-reducing strategies such as ECTCM should be used when possible and optimized in accordance with the As Low As Reasonably Achievable (ALARA) principle. The LNT hypothesis suggests that the extent of dose reduction will be paralleled by a commensurate decrease in the LAR of cancer incidence. Adequate beta blockade is imperative, not just to improve image quality but also to improve dose reduction from ECTCM.29
The development and evaluation of additional dose-reduction approaches for CTCA, such as prospectively gated step-and-shoot scan protocols, single gantry rotation whole heart imaging, multiple source scanning, more efficient ECTCM, and breast shielding, are vital and active areas of current research. Particular attention should be given to the avoidance of unnecessary repeat studies. The LAR estimates here are for a single CTCA scan; patients may have multiple tests over their lifetimes, and in BEIR VII's framework the risks are additive. The risk of cancer needs to be weighed against the potential benefits of CT in the management of patients with suspected or known cardiovascular disease.
Conclusion 
This study found that the LAR of cancer incidence associated with radiation exposure from CTCA (estimated using the approach of BEIR VII) varies widely, depending on age, sex, and protocol. Risk increases with combined cardiac and aortic scanning, especially in men, and decreases with ECTCM. The careful selection of patients for CT and the careful optimization of scan protocol in patients referred for testing can help to minimize cancer risk.

